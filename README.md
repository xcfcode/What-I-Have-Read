# What I Have Read


* [What I Have Read](#what-i-have-read)
  * [Slides](#slides)
     * [Summarization](#Summarization)
     * [Presentation](#presentation)
     * [Paper slides](#paper-slides)
     * [Notes](#notes)
  * [Contrastive Learning](./Contrastive-Learning.md)
  * [Cross-Lingual](./Cross-Lingual.md)
  * [Cognitive Modeling and Computational Linguistics](./CCL.md)
  * [Data Augmentation](./Data-Augmentation.md)
  * [Dialogue](./Dialogue.md)
  * [Generative Adversarial Networks (GAN)](./Generative-Adversarial-Networks.md)
  * [General-Purpose AI](./General-Purpose-AI.md)
  * [Graph Neural Networks (GNN)](./Graph-Neural-Networks.md)
  * [Knowledge Distillation](./Knowledge-Distillation.md)
  * [Meta Learning](./Meta-Learning.md)
  * [Multi-Modal](./Multi-Modal.md)
  * [Natural Language Generation (NLG)](./Natural-Language-Generation.md)
  * [Pre-trained Language Models (PLMs)](./Pre-train-Based.md)
  * [Retrieval-augmented NLP](./RA-NLP.md)
  * [Recommendation](./Recommendation.md)
  * [Reinforcement Learning](./Reinforcement-Learning.md)
  * [Scientific Document Processing](./SDP.md)
  * [Survey](./Survey.md)
  * [Summarization](./Summarization.md)
  * [Sentence Embedding](./Sentence_Embedding.md)
  * [Others](./Others.md)
  
## Slides

### Summarization
Please refer to [Summarization-Papers](https://github.com/xcfcode/Summarization-Papers).

### Presentation
* [Prompt Survey](slides/presentation/Prompt-part1.pdf)
* [Dialogue Summarization](http://xcfeng.net/res/presentation/Dialogue_Summarization.pdf)
* [Efficient Transformers](slides/presentation/Efficient_Transformers.pdf)
* [Data Augmentation](slides/presentation/Data_Augmentation.pdf)
* [Event Extraction](slides/presentation/Event%20Extraction.pdf)
* [Meta Learning](slides/presentation/Meta%20Learning.pdf)
* [Advanced pre-training language models a brief introduction](slides/presentation/Advanced%20pre-training%20language%20models%20a%20brief%20introduction.pdf)
* [Graph Neural Networks](slides/presentation/Graph%20Neural%20Networks.pdf)
* [Knowledge Distillation](slides/presentation/Knowledge%20Distillation.pdf)
* [Non-Autoregressive Decoding](slides/presentation/Non-Autoregressive%20Decoding.pdf)

### Paper slides
* [ICLR21-Contrastive Learning with Adversarial Perturbations for Conditional Text Generation](slides/paper-slides/Contrastive%20Learning%20with%20Adversarial%20Perturbations%20for%20Conditional%20Text%20Generation.pdf)
* [ACL21-Making Pre-trained Language Models Better Few-shot Learners](slides/paper-slides/Making%20Pre-trained%20Language%20Models%20Better%20Few-shot%20Learners.pdf)
* [EMNLP20-Group-wise Contrastive Learning for Neural Dialogue Generation](slides/paper-slides/group-wise-contrastive-learning-for-neural-dialogue-generation.pdf)
* [WWW20-Heterogeneous Graph Transformer](slides/paper-slides/Heterogeneous-Graph-Transformer.pdf)
* [ICLR20-Plug and Play Language Model- A Simple Baseline for Controlled Language Generation](slides/paper-slides/Plug%20and%20Play%20Language%20Model-%20A%20Simple%20Baseline%20for%20Controlled%20Language%20Generation.pdf)
* [ACL19-A Simple Theoretical Model of Importance for Summarization](slides/paper-slides/A%20Simple%20Theoretical%20Model%20of%20Importance%20for%20Summarization.pdf)
* [ACL19-Multimodal Abstractive Summarization for How2 Videos](slides/paper-slides/Multimodal%20Abstractive%20Summarization%20for%20How2%20Videos.pdf)
* [NIPS19-Episodic Memory in Lifelong Language Learning](slides/paper-slides/Episodic%20Memory%20in%20Lifelong%20Language%20Learning.pdf)
* [EMNLP19-DialogueGCN-A Graph Convolutional Neural Network for Emotion Recognition in Conversation](slides/paper-slides/DialogueGCN-A%20Graph%20Convolutional%20Neural%20Network%20for%20Emotion%20Recognition%20in%20Conversation.pdf)
* [ACL19-Dynamically Fused Graph Network for Multi-hop Reasoning](slides/paper-slides/Dynamically%20Fused%20Graph%20Network%20for%20Multi-hop%20Reasoning.pdf)
* [NAACL19-Linguistic Knowledge and Transferability of Contextual Representations](slides/paper-slides/Linguistic%20Knowledge%20and%20Transferability%20of%20Contextual%20Representations.pdf)
* [NAACL19-Text Generation from Knowledge Graphs with Graph Transformers](slides/paper-slides/Text%20Generation%20from%20Knowledge%20Graphs%20with%20Graph%20Transformers.pdf)
* [The Curious Case of Neural Text Degeneration ](slides/paper-slides/The%20Curious%20Case%20of%20Neural%20Text%20Degeneration.pdf)
* [EMNLP18-Multi-Domain Neural Machine Translation with Word-Level Domain Context Discrimination](slides/paper-slides/Multi-Domain%20Neural%20Machine%20Translation%20with%20Word-Level%20Domain%20Context%20Discrimination.pdf)
* [EMNLP18-Commonsense for Generative Multi-Hop Question Answering Tasks](slides/paper-slides/Commonsense%20for%20Generative%20Multi-Hop%20Question%20Answering%20Tasks.pdf)
* [IJCAI18-Commonsense Knowledge Aware Conversation Generation with Graph Attention](slides/paper-slides/Commonsense%20Knowledge%20Aware%20Conversation%20Generation%20with%20Graph%20Attention.pdf)
* [AAAI18-Emotional Chatting Machine Emotional Conversation Generation with Internal and External Memory](slides/paper-slides/Emotional%20Chatting%20Machine%20Emotional%20Conversation%20Generation%20with%20Internal%20and%20External%20Memory.pdf)
* [EMNLP18-Learning Neural Templates for Text Generation](slides/paper-slides/Learning%20Neural%20Templates%20for%20Text%20Generation.pdf)
* [ACL18-Learning to Ask Questions in Open-domain Conversational Systems with Typed Decoders ](slides/paper-slides/Learning%20to%20Ask%20Questions%20in%20Open-domain%20Conversational%20Systems%20with%20Typed%20Decoders%20.pdf)
* [ACL17-Semi-Supervised QA with Generative Domain-Adaptive Nets](slides/paper-slides/Semi-Supervised%20QA%20with%20Generative%20Domain-Adaptive%20Nets.pdf)
* [ACL17-Deep Multitask Learning for Semantic Dependency Parsing](slides/paper-slides/Deep%20Multitask%20Learning%20for%20Semantic%20Dependency%20Parsing.pdf)

### Notes
* [EMNLP19 and NIPS19 Notes](slides/notes/EMNLP19_and_NIPS19_Notes.pdf)
* [Cross-Lingual](./slides/notes/x-lingual-v1.0.pdf)
* [GAN in Text Generation](slides/notes/GAN%20in%20Text%20Generation.pdf)
* [Boosting](slides/notes/Boosting.pdf)
* [HMM](slides/notes/HMM.pdf)
* [The Maximum Entropy Model](slides/notes/The%20Maximum%20Entropy%20Model.pdf)
* [ConceptNet](slides/notes/ConceptNet.pdf)

























