# Contrastive Learning NLP Papers

> The main idea of contrastive learning is to learn representations such that similar samples stay close to each other, while dissimilar ones are far apart. Contrastive learning can be applied to both supervised and unsupervised data and has been shown to achieve good performance on a variety of vision and language tasks. *[Contrastive Representation Learning](https://lilianweng.github.io/lil-log/2021/05/31/contrastive-representation-learning.html)*

## Blog
* [张俊林：对比学习在微博内容表示的应用](https://mp.weixin.qq.com/s/MteoquDoks4kuVPA9jzT_Q)
* [Contrastive Representation Learning](https://lilianweng.github.io/lil-log/2021/05/31/contrastive-representation-learning.html)
* [Contrastive Self-Supervised Learning](https://ankeshanand.com/blog/2020/01/26/contrative-self-supervised-learning.html)
* [对比学习（Contrastive Learning）相关进展梳理](https://zhuanlan.zhihu.com/p/141141365)
* [赛尔笔记 | 对比学习简述](https://mp.weixin.qq.com/s/v5p9QA3vDl-WTF3-7shp4g)

## Papers
1. **A Contrastive Framework for Neural Text Generation** *Yixuan Su, Tian Lan, Yan Wang, Dani Yogatama, Lingpeng Kong, Nigel Collier* [[pdf]](https://arxiv.org/abs/2202.06417) [[code]](https://github.com/yxuansu/SimCTG)
1. **SimCSE: Simple Contrastive Learning of Sentence Embeddings** *Tianyu Gao, Xingcheng Yao, Danqi Chen* [[pdf]](https://arxiv.org/abs/2104.08821) [[code]](https://github.com/princeton-nlp/SimCSE)
1. **ConSERT: A Contrastive Framework for Self-Supervised Sentence Representation Transfer** *Yuanmeng Yan, Rumei Li, Sirui Wang, Fuzheng Zhang, Wei Wu, Weiran Xu* `ACL 2021` [[pdf]](https://arxiv.org/abs/2105.11741) [[code]](https://github.com/yym6472/ConSERT)
2. **CLINE: Contrastive Learning with Semantic Negative Examples for Natural Language Understanding** *Dong Wang, Ning Ding, Piji Li, Hai-Tao Zheng* `ACL 2021` [[pdf]](https://arxiv.org/abs/2107.00440) [[code]](https://github.com/kandorm/CLINE)
2. **Supervised Contrastive Learning for Pre-trained Language Model Fine-tuning** *Beliz Gunel, Jingfei Du, Alexis Conneau, Ves Stoyanov* `ICLR 2021` [[pdf]](https://arxiv.org/abs/2011.01403)
1. **SimCLS: A Simple Framework for Contrastive Learning of Abstractive Summarization** *Yixin Liu, Pengfei Liu* `ACL2021 short` [[pdf]](https://arxiv.org/abs/2106.01890) [[code]](https://github.com/yixinL7/SimCLS) ![](https://img.shields.io/badge/-TG-orange)
1. **Contrastive Learning with Adversarial Perturbations for Conditional Text Generation** *Seanie Lee, Dong Bok Lee, Sung Ju Hwang* `ICLR21` [[pdf]](https://arxiv.org/abs/2012.07280) ![](https://img.shields.io/badge/-TG-orange)
2. **Learning with Contrastive Examples for Data-to-Text Generation** *Yui Uehara, Tatsuya Ishigaki, Kasumi Aoki, Hiroshi Noji, Keiichi Goshima, Ichiro Kobayashi, Hiroya Takamura, Yusuke Miyao* `COLING 2020` [[pdf]](https://aclanthology.org/2020.coling-main.213/) [[code]](https://github.com/aistairc/contrastive_data2text) ![](https://img.shields.io/badge/-TG-orange)
1. **DeepChannel: Salience Estimation by Contrastive Learning for Extractive Document Summarization** *Jiaxin Shi, Chen Liang, Lei Hou, Juanzi Li, Zhiyuan Liu, Hanwang Zhang* `AAAI19` [[pdf]](https://arxiv.org/abs/1811.02394) [[code]](https://github.com/lliangchenc/DeepChannel)
3. **Unsupervised Reference-Free Summary Quality Evaluation via Contrastive Learning** *Hanlu Wu, Tengfei Ma, Lingfei Wu, Tariro Manyumwa, Shouling Ji* `EMNLP 2020` [[pdf]](https://arxiv.org/abs/2010.01781) [[code]](https://github.com/whl97/LS-Score)
4. **Group-wise Contrastive Learning for Neural Dialogue Generation** *Hengyi Cai, Hongshen Chen, Yonghao Song, Zhuoye Ding, Yongjun Bao, Weipeng Yan, Xiaofang Zhao* `EMNLP 2020` [[pdf]](https://arxiv.org/abs/2009.07543) [[code]](https://github.com/hengyicai/ContrastiveLearning4Dialogue) ![](https://img.shields.io/badge/-TG-orange)
4. **Contrastive Attention Mechanism for Abstractive Sentence Summarization** *Xiangyu Duan, Hongfei Yu, Mingming Yin, Min Zhang, Weihua Luo, Yue Zhang* `EMNLP 2019` [[pdf]](https://www.aclweb.org/anthology/D19-1301/) [[code]](https://github.com/travel-go/Abstractive-Text-Summarization)
5. **Pretraining with Contrastive Sentence Objectives Improves Discourse Performance of Language Models** *Dan Iter, Kelvin Guu, Larry Lansing, Dan Jurafsky* `ACL 2020` [[pdf]](https://arxiv.org/abs/2005.10389) [[code]](https://github.com/google-research/language)
6. **Contrastive Self-Supervised Learning for Commonsense Reasoning** *Tassilo Klein, Moin Nabi* `ACL 2020` [[pdf]](https://arxiv.org/abs/2005.00669) [[code]](https://github.com/SAP-samples/acl2020-commonsense)
7. **CERT: Contrastive Self-supervised Learning for Language Understanding** *Hongchao Fang, Sicheng Wang, Meng Zhou, Jiayuan Ding, Pengtao Xie* [[pdf]](https://arxiv.org/abs/2005.12766)
8. **Contrastive Learning of Emoji-based Representations for Resource-Poor Languages** *Nurendra Choudhary, Rajat Singh, Ishita Bindlish, Manish Shrivastava* [[pdf]](https://arxiv.org/abs/1804.01855)


